---
layout: post
title: "[하이브] 핵심 개념"
categories: data
---

1. this unordered seed list will be replaced by toc as unordered list
{:toc}

## 소개

- 한마디로 SQL on Hadoop
- 데이터베이스: 테이블 이름 구별을 위한 일종의 네임스페이스
- 테이블: hdfs 상에 저장된 파일과 디렉토리 구조에 대한 메타 정보

## 구성요소

- ui: cli, beeline
- driver: 쿼리 입력 받아서 작업 처리
- compiler: 메타 스토어 참고해서 쿼리 실행 계획 생성
- metastore: 디비, 테이블, 파티션 정보 등 저장
- execution engine: 컴파일러의 의해 생성된 실행 계획 수행

## 실행 순서

- 드라이버가 사용자가 제출한 sql 받아서 컴파일러에 전달
- 컴파일러는 메타스토어를 참고해 sql plan 작성
- 컴파일된 sql 로 실행 엔진이 수행
- 실행엔진은 yarn에게 job 전달
- 결과 반환

## hive server 2

다른 언어로 개발된 클라이언트와 연동 담당

## beeline

cli 와 비슷. 원격 하이브 서버2에 접속 가능

## 메타스토어

디비, 테이블, 파티션 정보 등 저장

## 파티션

- 폴더 구조로 데이터를 분할하여 저장. 보통 dt 에 사용
- 고정: 데이터를 입력하는 시점에 파티션 정보 전달
- 동적: 컬럼의 정보를 이용하여 파티션이 생성

## 버켓

CLUSTERED BY 컬럼명. 특정 컬럼을 지정한 수만큼 나눠서 파일로 저장. SMB 조인으로 처리 가능.

## 테이블 포맷

DELIMITED: 데이터를 구분자를 사용해서 분리

## 스큐

- 하나의 컬럼에 특정 데이터가 몰릴 때 사용
- 예를 들어, nums 컬럼에 1~1000 데이터가 들어오는데 유독 1,2 가 많이 들어온다고 하면,
- 파티션을 쓴다면 1000개를 만들겠지만, 스큐는 1,2 그외 나머지 이렇게 나눠서 총 3개로 구분
- 이러면 네임노드 관점에서 좋음

## 서데

- hdfs 에 있는 데이터를 읽고 쓸때 해석하는 방법을 제공(serial, deserial)
- orc, parquet, csv, json 등 제공

## 저장 포맷

STORED AS로 저장 형식 지정. textfile, parquet, orc 등

## 하이브 조인 기법

- 셔플 조인(머지 조인): 맵 단계에서 각 테이블을 읽고, 파티션 키를 조인 키로 설정하여 셔플 단계에서 조인 키를 기준으로 리듀서로 데이터가 이동. 가장 느림
- 맵 조인(브로드캐스트 조인, 맵사이드 조인): 둘 중 한 쪽을 메모리에 올려서 처리
- SMB 조인: 조인 테이블이 버케팅 되어 있을 때 사용 가능. 버케팅 된 키의 정보를 이용해서 빠르게 조인 가능

## 하이브 정렬 기법

- ORDER BY: 모든 데이터를 정렬. 데이터 크기가 크면 OOM 에러 가능성. LIMIT 을 쓰자.
- SORT BY: 리듀서 수만큼, 리듀서 별로 데이터를 정렬. 리듀서 수가 1이면 ORDER BY 랑 같음
- DISTRIBUTE BY: 리듀서로 전달 시, 리듀서 별로 같은 값이 전달. group by 와 비슷한..
- CLUSTER BY: DISTRIBUTE BY + SORT BY. 14132 가 각각 121, 43 로 나뉘고 112, 34 형태로 정렬

## 튜닝

- TEZ 엔진 사용(맵 처리 결과를 메모리에 저장)
- ORC 포맷 사용(컬럼 기반, 속도 빠름, 압축률 높음)
- 벡터화 사용(한번에 1024행 처리하여 속도 높음)
- 파티셔닝, 버케팅 사용
- CBO 활성화(쿼리 최적화)
- yarn 작업 큐 여러 개 사용